 
<!doctype html>
<html>
    <head>
        <!-- BOOTSTRAP CORE STYLE  -->
        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
        <!-- GOOGLE FONT -->
        <link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css' crossorigin="anonymous" />

        <!-- BOOTSTRAP JS -->
        <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
        <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    
        <!-- CUSTOM STYLE CSS -->
       
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

        <!-- Page description -->   


        <!-- Page keywords -->
        

        <!-- Page author -->
        
        <meta name="author" content="Masaya Kawamura" />
        

        <!-- Site title -->
        
        
            <title>Demonstration of Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band Generation and Inverse Short-Time Fourier Transform - Masaya Kawamura</title>
        
        

        
            
            
        

    </head>
    <body>


        <section class="jumbotron text-center">
    <div class="container">
        
            <h1 class="jumbotron-heading">Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band Generation and Inverse Short-Time Fourier Transform</h1>
        
        
            <p class="lead">
                Masaya Kawamura<sup>1*</sup>, Yuma Shirahata<sup>2</sup>, Ryuichi Yamamoto<sup>2</sup>, Kentaro Tachibana<sup>2</sup>
            </p>
            <p class="lead">
                <sup>1</sup>The University of Tokyo, Tokyo, Japan<br>
                <sup>2</sup>LINE Corp., Japan.<br>
                <sup>*</sup>Work performed during an internship at LINE corporation<br><br>

            </p>
            <p class="lead">
                Accepted to ICASSP 2023<br>
                [<a href="https://arxiv.org/abs/2210.15975">Paper</a>] [<a href="https://github.com/MasayaKawamura/MB-iSTFT-VITS">Code</a>]
            </p>
            


        
    </div>
</section>
        
            <p><link rel="stylesheet" type="text/css" href="style.css"></p>
<div class="container">
    <div class="row"><h2>Abstract</h2></div>
    
    <div class="row">
        <p class="lead">
         We propose a lightweight end-to-end text-to-speech model using multi-band generation 
         and inverse short-time Fourier transform. Our model is based on VITS, a high-quality 
         end-to-end text-to-speech model, but adopts two changes for more efficient inference: 1) the most 
         computationally expensive component is partially replaced with a simple inverse short-time Fourier 
         transform, and 2) multi-band generation, with fixed or trainable synthesis filters, is used to generate 
         waveforms. Unlike conventional lightweight models, which employ optimization or knowledge distillation separately 
         to train two cascaded components, our method enjoys the full benefits of end-to-end optimization. Experimental results 
         show that our model synthesized speech as natural as that synthesized by VITS, while achieving a real-time factor of 
         0.066 on an Intel Core i7 CPU, 4.1 times faster than VITS. Moreover, a smaller version of the model significantly 
         outperformed a lightweight baseline model with respect to both naturalness and inference speed. 
         Code and audio samples are available from <a href="https://github.com/MasayaKawamura/MB-iSTFT-VITS">https://github.com/MasayaKawamura/MB-iSTFT-VITS</a>.
        </p>
    </div>
    <div align="center">
        <img src="images/proposed_figure.png" width="100%">
        <figcaption>Architecture of multi-band iSTFT VITS and multi-stream iSTFT VITS.</figcaption>
    </div>
    <div class="row"><h2>Demo</h2></div>
    <div class="row">
        <p class="lead">
         This is an accompanying page and includes some examples of the synthesized speech obtained with the proposed and conventional methods.
         The groundtruth audio clips are from the LJ speech dataset [1].  
         These clips are not included in the training data. 
        </p>
    </div>
</div>
<p><br></p>

    <table   style="table-layout: fixed;">
        <thead>
            <tr>
                <th style="vertical-align:middle" style="text-align: center" class="td_fixed">Model</th>
                <th style="text-align: center"  >Text: Weedon and Lecasser to twelve <br>and six months respectively in Coldbath Fields.</th>
                <th style="text-align: center"  >Text: There among the ruins <br>they still live in the same kind of houses,</th>
                <th style="text-align: center"  >Text: Mrs. De Mohrenschildt thought that Oswald,</th>
                <th style="text-align: center" >Text: carbohydrates (starch, cellulose) and fats.</th>

            </tr>
        </thead>
        <tbody>


<tr>
    <td style="vertical-align:middle" style="text-align: center"  class="td_fixed">Ground truth</td>
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ012-0015/GT_LJ012-0015.mp3">
        </audio>
    </td >
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ028-0410/GT_LJ028-0410.mp3">
        </audio>
    </td>
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ045-0096/GT_LJ045-0096.mp3">
        </audio>
    </td>
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ026-0054/GT_LJ026-0054.mp3">
        </audio>
    </td>
</tr>


<tr>
<td style="vertical-align:middle" style="text-align: center"  class="td_fixed">VITS [2]</td>
<td >
    <audio controls preload="metadata" src="demo/Sample_LJ012-0015/VITS_LJ012-0015.mp3">
    </audio>
</td >
<td >
    <audio controls preload="metadata" src="demo/Sample_LJ028-0410/VITS_LJ028-0410.mp3">
    </audio>
</td>
<td >
    <audio controls preload="metadata" src="demo/Sample_LJ045-0096/VITS_LJ045-0096.mp3">
    </audio>
</td>
<td >
    <audio controls preload="metadata" src="demo/Sample_LJ026-0054/VITS_LJ026-0054.mp3">
    </audio>
</td>
</tr>

<tr>
    <td style="vertical-align:middle" style="text-align: center"  class="td_fixed">Nix-TTS [3]</td>
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ012-0015/NixTTS_LJ012-0015.mp3">
        </audio>
    </td >
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ028-0410/NixTTS_LJ028-0410.mp3">
        </audio>
    </td>
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ045-0096/NixTTS_LJ045-0096.mp3">
        </audio>
    </td>
    <td >
        <audio controls preload="metadata" src="demo/Sample_LJ026-0054/NixTTS_LJ026-0054.mp3">
        </audio>
    </td>
  

    </tr>
    <tr>
        <td style="vertical-align:middle" style="text-align: center"  class="td_fixed">iSTFT-VITS</td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ012-0015/VITS+iSTFTNet_LJ012-0015.mp3">
            </audio>
        </td >
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ028-0410/VITS+iSTFTNet_LJ028-0410.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ045-0096/VITS+iSTFTNet_LJ045-0096.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ026-0054/VITS+iSTFTNet_LJ026-0054.mp3">
            </audio>
        </td>
      
    
    </tr>
    <tr>
        <td style="vertical-align:middle" style="text-align: center"  class="td_fixed"><u>MB-iSTFT-VITS</u></td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ012-0015/VITS+Multiband_iSTFTNet_LJ012-0015.mp3">
            </audio>
        </td >
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ028-0410/VITS+Multiband_iSTFTNet_LJ028-0410.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ045-0096/VITS+Multiband_iSTFTNet_LJ045-0096.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ026-0054/VITS+Multiband_iSTFTNet_LJ026-0054.mp3">
            </audio>
        </td>
      
    
    </tr>
    <tr>
        <td style="vertical-align:middle" style="text-align: center"  class="td_fixed"><u>MS-iSTFT-VITS</u></td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ012-0015/VITS+Multistream_iSTFTNet_LJ012-0015.mp3">
            </audio>
        </td >
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ028-0410/VITS+Multistream_iSTFTNet_LJ028-0410.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ045-0096/VITS+Multistream_iSTFTNet_LJ045-0096.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ026-0054/VITS+Multistream_iSTFTNet_LJ026-0054.mp3">
            </audio>
        </td>
      
    
    </tr>
    <tr>
        <td style="vertical-align:middle" style="text-align: center"  class="td_fixed">Mini-VITS</td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ012-0015/MiniVITS_LJ012-0015.mp3">
            </audio>
        </td >
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ028-0410/MiniVITS_LJ028-0410.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ045-0096/MiniVITS_LJ045-0096.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ026-0054/MiniVITS_LJ026-0054.mp3">
            </audio>
        </td>
      
    
    </tr>
    <tr>
        <td style="vertical-align:middle" style="text-align: center"  class="td_fixed">Mini-iSTFT-VITS</td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ012-0015/MiniVITS+iSTFTNet_LJ012-0015.mp3">
            </audio>
        </td >
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ028-0410/MiniVITS+iSTFTNet_LJ028-0410.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ045-0096/MiniVITS+iSTFTNet_LJ045-0096.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ026-0054/MiniVITS+iSTFTNet_LJ026-0054.mp3">
            </audio>
        </td>
      
      
    
    </tr>
    <tr>
        <td style="vertical-align:middle" style="text-align: center"  class="td_fixed"><u>Mini-MB-iSTFT-VITS</u></td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ012-0015/MiniVITS+Multiband_iSTFTNet_LJ012-0015.mp3">
            </audio>
        </td >
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ028-0410/MiniVITS+Multiband_iSTFTNet_LJ028-0410.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ045-0096/MiniVITS+Multiband_iSTFTNet_LJ045-0096.mp3">
            </audio>
        </td>
        <td >
            <audio controls preload="metadata" src="demo/Sample_LJ026-0054/MiniVITS+Multiband_iSTFTNet_LJ026-0054.mp3">
            </audio>
        </td>
      
    
    </tr>
                </tbody>
            </table>


<div class="container">
    <h1>References</h1>
    <div>
        [1] K. Ito, "The LJ speech dataset", <a href= "https://keithito.com/LJ-Speech-Dataset/" >https://keithito.com/LJ-Speech-Dataset/</a>, 2017.
        <br>
        [2] J. Kim, J. Kong, J. Son, "Conditional variational autoencoder with adversarial learning for end-to-end text-to-speech," in <em>Proc. ICML</em>, 2021, pp. 5530-5540.
        <br>
        [3] R. Chevi, R. E. Prasojo, A. F. Aji, A. Tjandra, S. Sakti, "Nix-TTS: Lightweight and end-to-end text-to-speech via module-wise distillation", in <em>Proc. SLT</em>, 2023, pp. 970–976.
        

    </div>
</div>
        
    </body>
</html>
